{
 "cells": [
  {
   "cell_type": "raw",
   "id": "e0b065d7-df7f-48d1-a679-badc71c53d03",
   "metadata": {},
   "source": [
    "                                    assignment pandas advance-2"
   ]
  },
  {
   "cell_type": "raw",
   "id": "5505d1ac-6ebf-4c79-b6b2-74bea45e7e6e",
   "metadata": {},
   "source": [
    "Q1. Write a code to print the data present in the second row of the dataframe, df."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "66850a29-a832-41c4-843c-ee21d1028041",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "course_name    Machine Learning\n",
      "duration                      3\n",
      "Name: 1, dtype: object\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "course_name = ['Data Science', 'Machine Learning', 'Big Data', 'Data Engineer']\n",
    "duration = [2, 3, 6, 4]\n",
    "df = pd.DataFrame(data={'course_name': course_name, 'duration': duration})\n",
    "\n",
    "second_row_data = df.iloc[1]\n",
    "print(second_row_data)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "58449cb6-a237-4d93-92f0-b368fb619917",
   "metadata": {},
   "source": [
    "Q2. What is the difference between the functions loc and iloc in pandas.DataFrame?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e3bb6c9e-032c-4124-a4bb-dae3ebaefb16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "5\n",
      "      A  B  C\n",
      "row1  1  4  7\n",
      "row2  2  5  8\n",
      "      A  B  C\n",
      "row1  1  4  7\n",
      "row2  2  5  8\n"
     ]
    }
   ],
   "source": [
    "\"\"\"  In pandas, both `loc` and `iloc` are used for indexing and selecting data from a DataFrame,\n",
    "    but they have different ways of referencing data\n",
    "    \n",
    "    difference between the two:-\n",
    "    \n",
    "    1.`loc` (Label-based Indexing):\n",
    "        >`loc` is used for selecting data based on labels or index values. \n",
    "         It uses labels to specify the rows and columns you want to select.\n",
    "            \n",
    "    >You can pass row labels and column labels as arguments to `loc`.\n",
    "    >The syntax is: `df.loc[row_label, column_label]`.\n",
    "    \n",
    "    \n",
    "    2.`iloc` (Integer-based Indexing):\n",
    "        \n",
    "       >`iloc` is used for selecting data based on integer positions. \n",
    "         It uses integer indices to specify the rows and columns you want to select. \n",
    "      > You can pass integer indices (0-based) to `iloc`.\n",
    "      >The syntax is: `df.iloc[row_index, column_index]`.\n",
    "    \n",
    "    \n",
    "    examples:- \"\"\"\n",
    "    \n",
    "import pandas as pd\n",
    "\n",
    "data = {'A': [1, 2, 3],\n",
    "        'B': [4, 5, 6],\n",
    "        'C': [7, 8, 9]}\n",
    "df = pd.DataFrame(data, index=['row1', 'row2', 'row3'])\n",
    "\n",
    "print(df.loc['row2', 'B'])  \n",
    "\n",
    "print(df.iloc[1, 1])  \n",
    "\n",
    "print(df.loc['row1':'row2', :])  \n",
    "print(df.iloc[0:2, :])  "
   ]
  },
  {
   "cell_type": "raw",
   "id": "126d1ea6-ddaa-41ed-9013-2e3cdc824435",
   "metadata": {},
   "source": [
    "Q3. Reindex the given dataframe using a variable, reindex = [3,0,1,2] and store it in the variable, new_df\n",
    "    then find the output for both new_df.loc[2] and new_df.iloc[2].\n",
    "    \n",
    "    Did you observe any difference in both the outputs? If so then explain it.\n",
    "    Consider the below code to answer further questions:\n",
    "    \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "columns = ['column_1', 'column_2', 'column_3', 'column_4', 'column_5', 'column_6']\n",
    "indices = [1,2,3,4,5,6]\n",
    "#Creating a dataframe:\n",
    "df1 = pd.DataFrame(np.random.rand(6,6), columns = columns, index = indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f5295f61-f000-496d-bdb2-bedd3cc25587",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output of new_df.loc[2]:\n",
      "column_1    0.278746\n",
      "column_2    0.035010\n",
      "column_3    0.802707\n",
      "column_4    0.588439\n",
      "column_5    0.969939\n",
      "column_6    0.623092\n",
      "Name: 2, dtype: float64\n",
      "\n",
      "Output of new_df.iloc[2]:\n",
      "column_1    0.535791\n",
      "column_2    0.401078\n",
      "column_3    0.182735\n",
      "column_4    0.349600\n",
      "column_5    0.998349\n",
      "column_6    0.998868\n",
      "Name: 1, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "columns = ['column_1', 'column_2', 'column_3', 'column_4', 'column_5', 'column_6']\n",
    "indices = [1, 2, 3, 4, 5, 6]\n",
    "\n",
    "\n",
    "df1 = pd.DataFrame(np.random.rand(6, 6), columns=columns, index=indices)\n",
    "\n",
    "\n",
    "reindex = [3, 0, 1, 2]\n",
    "new_df = df1.reindex(reindex)\n",
    "\n",
    "\n",
    "print(\"Output of new_df.loc[2]:\")\n",
    "print(new_df.loc[2])\n",
    "\n",
    "print(\"\\nOutput of new_df.iloc[2]:\")\n",
    "print(new_df.iloc[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b8fc917-61fc-4324-9a1b-1c4a296985cc",
   "metadata": {},
   "source": [
    " differences between the two outputs:-\n",
    "    \n",
    "   1.Output of `new_df.loc[2]`:\n",
    "    \n",
    "    > This selects the row with the label/index 2 after reindexing.\n",
    "      However, due to the reindexing, the label/index 2 now corresponds\n",
    "        to the original row with label/index 1.\n",
    "        \n",
    "    >The output contains the data for the row where the original index was 1.\n",
    "    \n",
    "    2.Output of `new_df.iloc[2]`:\n",
    "        \n",
    "       >This selects the row at integer position 2 after reindexing.\n",
    "         In this case, the third row after reindexing corresponds to the\n",
    "         original row with index 2. \n",
    "            \n",
    "        >The output contains the data for the row where the original index was 2.\n",
    "        \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "raw",
   "id": "fdea48a1-3cf8-4c54-be93-5115336ca4de",
   "metadata": {},
   "source": [
    "Q4. Write a code to find the following statistical measurements for the above dataframe df1:\n",
    "   (i) mean of each and every column present in the dataframe.\n",
    "   (ii) standard deviation of column, ‘column_2’"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2c0e4f7d-c10c-4d5b-9f93-b59e427b0f64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean of each column:\n",
      "column_1    0.456679\n",
      "column_2    0.523353\n",
      "column_3    0.398523\n",
      "column_4    0.641989\n",
      "column_5    0.700328\n",
      "column_6    0.469950\n",
      "dtype: float64\n",
      "\n",
      "Standard deviation of column 'column_2':\n",
      "0.29137518265997864\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "columns = ['column_1', 'column_2', 'column_3', 'column_4', 'column_5', 'column_6']\n",
    "indices = [1, 2, 3, 4, 5, 6]\n",
    "\n",
    "\n",
    "df1 = pd.DataFrame(np.random.rand(6, 6), columns=columns, index=indices)\n",
    "\n",
    "column_means = df1.mean()\n",
    "print(\"Mean of each column:\")\n",
    "print(column_means)\n",
    "\n",
    "column_2_std = df1['column_2'].std()\n",
    "print(\"\\nStandard deviation of column 'column_2':\")\n",
    "print(column_2_std)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1af862d6-67c8-4292-9a53-85e577b3df46",
   "metadata": {},
   "source": [
    "Explanation:\n",
    "    \n",
    "    (i) The code calculates the mean of each column using the. \n",
    "         mean() method of the DataFrame.\n",
    "         It provides the mean value for every column present in the DataFrame.\n",
    "            \n",
    "    (ii) The code calculates the standard deviation of the 'column_2' using the .\n",
    "         std() method applied to that specific column.\n",
    "         It calculates and outputs the standard deviation value for the specified column.\n",
    "            \n",
    "    "
   ]
  },
  {
   "cell_type": "raw",
   "id": "63797b69-9954-45af-be21-0ce9f2078fe7",
   "metadata": {},
   "source": [
    "Q5. Replace the data present in the second row of column, ‘column_2’ by a string variable then find the\n",
    "    mean of column, column_2.\n",
    "    \n",
    "If you are getting errors in executing it then explain why.\n",
    "[Hint: To replace the data use df1.loc[] and equate this to string data of your choice.]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "312cbccb-7090-4e45-947a-4108331f906c",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for +: 'float' and 'str'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 10\u001b[0m\n\u001b[1;32m      6\u001b[0m df1 \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mrand(\u001b[38;5;241m6\u001b[39m,\u001b[38;5;241m6\u001b[39m), columns \u001b[38;5;241m=\u001b[39m columns, index \u001b[38;5;241m=\u001b[39m indices)\n\u001b[1;32m      8\u001b[0m df1\u001b[38;5;241m.\u001b[39mloc[\u001b[38;5;241m2\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcolumn_2\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstring_value\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m---> 10\u001b[0m mean \u001b[38;5;241m=\u001b[39m \u001b[43mdf1\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcolumn_2\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmean\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMean of column \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcolumn_2\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28mprint\u001b[39m(mean)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/core/generic.py:11847\u001b[0m, in \u001b[0;36mNDFrame._add_numeric_operations.<locals>.mean\u001b[0;34m(self, axis, skipna, level, numeric_only, **kwargs)\u001b[0m\n\u001b[1;32m  11829\u001b[0m \u001b[38;5;129m@doc\u001b[39m(\n\u001b[1;32m  11830\u001b[0m     _num_doc,\n\u001b[1;32m  11831\u001b[0m     desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReturn the mean of the values over the requested axis.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m  11845\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m  11846\u001b[0m ):\n\u001b[0;32m> 11847\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mNDFrame\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmean\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskipna\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnumeric_only\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/core/generic.py:11401\u001b[0m, in \u001b[0;36mNDFrame.mean\u001b[0;34m(self, axis, skipna, level, numeric_only, **kwargs)\u001b[0m\n\u001b[1;32m  11393\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmean\u001b[39m(\n\u001b[1;32m  11394\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m  11395\u001b[0m     axis: Axis \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m|\u001b[39m lib\u001b[38;5;241m.\u001b[39mNoDefault \u001b[38;5;241m=\u001b[39m lib\u001b[38;5;241m.\u001b[39mno_default,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m  11399\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m  11400\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Series \u001b[38;5;241m|\u001b[39m \u001b[38;5;28mfloat\u001b[39m:\n\u001b[0;32m> 11401\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_stat_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m  11402\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmean\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnanops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnanmean\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskipna\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnumeric_only\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m  11403\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/core/generic.py:11353\u001b[0m, in \u001b[0;36mNDFrame._stat_function\u001b[0;34m(self, name, func, axis, skipna, level, numeric_only, **kwargs)\u001b[0m\n\u001b[1;32m  11343\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m  11344\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUsing the level keyword in DataFrame and Series aggregations is \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m  11345\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdeprecated and will be removed in a future version. Use groupby \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m  11348\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[1;32m  11349\u001b[0m     )\n\u001b[1;32m  11350\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_agg_by_level(\n\u001b[1;32m  11351\u001b[0m         name, axis\u001b[38;5;241m=\u001b[39maxis, level\u001b[38;5;241m=\u001b[39mlevel, skipna\u001b[38;5;241m=\u001b[39mskipna, numeric_only\u001b[38;5;241m=\u001b[39mnumeric_only\n\u001b[1;32m  11352\u001b[0m     )\n\u001b[0;32m> 11353\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_reduce\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m  11354\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskipna\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mskipna\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnumeric_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnumeric_only\u001b[49m\n\u001b[1;32m  11355\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/core/series.py:4816\u001b[0m, in \u001b[0;36mSeries._reduce\u001b[0;34m(self, op, name, axis, skipna, numeric_only, filter_type, **kwds)\u001b[0m\n\u001b[1;32m   4812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(\n\u001b[1;32m   4813\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSeries.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m does not implement \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkwd_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   4814\u001b[0m     )\n\u001b[1;32m   4815\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m np\u001b[38;5;241m.\u001b[39merrstate(\u001b[38;5;28mall\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m-> 4816\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdelegate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskipna\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mskipna\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/core/nanops.py:93\u001b[0m, in \u001b[0;36mdisallow.__call__.<locals>._f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     92\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m np\u001b[38;5;241m.\u001b[39merrstate(invalid\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m---> 93\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     94\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     95\u001b[0m     \u001b[38;5;66;03m# we want to transform an object array\u001b[39;00m\n\u001b[1;32m     96\u001b[0m     \u001b[38;5;66;03m# ValueError message to the more typical TypeError\u001b[39;00m\n\u001b[1;32m     97\u001b[0m     \u001b[38;5;66;03m# e.g. this is normally a disallowed function on\u001b[39;00m\n\u001b[1;32m     98\u001b[0m     \u001b[38;5;66;03m# object arrays that contain strings\u001b[39;00m\n\u001b[1;32m     99\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_object_dtype(args[\u001b[38;5;241m0\u001b[39m]):\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/core/nanops.py:155\u001b[0m, in \u001b[0;36mbottleneck_switch.__call__.<locals>.f\u001b[0;34m(values, axis, skipna, **kwds)\u001b[0m\n\u001b[1;32m    153\u001b[0m         result \u001b[38;5;241m=\u001b[39m alt(values, axis\u001b[38;5;241m=\u001b[39maxis, skipna\u001b[38;5;241m=\u001b[39mskipna, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[1;32m    154\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 155\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43malt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskipna\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mskipna\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    157\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/core/nanops.py:418\u001b[0m, in \u001b[0;36m_datetimelike_compat.<locals>.new_func\u001b[0;34m(values, axis, skipna, mask, **kwargs)\u001b[0m\n\u001b[1;32m    415\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m datetimelike \u001b[38;5;129;01mand\u001b[39;00m mask \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    416\u001b[0m     mask \u001b[38;5;241m=\u001b[39m isna(values)\n\u001b[0;32m--> 418\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskipna\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mskipna\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    420\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m datetimelike:\n\u001b[1;32m    421\u001b[0m     result \u001b[38;5;241m=\u001b[39m _wrap_results(result, orig_values\u001b[38;5;241m.\u001b[39mdtype, fill_value\u001b[38;5;241m=\u001b[39miNaT)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/core/nanops.py:706\u001b[0m, in \u001b[0;36mnanmean\u001b[0;34m(values, axis, skipna, mask)\u001b[0m\n\u001b[1;32m    703\u001b[0m     dtype_count \u001b[38;5;241m=\u001b[39m dtype\n\u001b[1;32m    705\u001b[0m count \u001b[38;5;241m=\u001b[39m _get_counts(values\u001b[38;5;241m.\u001b[39mshape, mask, axis, dtype\u001b[38;5;241m=\u001b[39mdtype_count)\n\u001b[0;32m--> 706\u001b[0m the_sum \u001b[38;5;241m=\u001b[39m _ensure_numeric(\u001b[43mvalues\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msum\u001b[49m\u001b[43m(\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype_sum\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    708\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m axis \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(the_sum, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mndim\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m    709\u001b[0m     count \u001b[38;5;241m=\u001b[39m cast(np\u001b[38;5;241m.\u001b[39mndarray, count)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/numpy/core/_methods.py:48\u001b[0m, in \u001b[0;36m_sum\u001b[0;34m(a, axis, dtype, out, keepdims, initial, where)\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_sum\u001b[39m(a, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, out\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, keepdims\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m     47\u001b[0m          initial\u001b[38;5;241m=\u001b[39m_NoValue, where\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[0;32m---> 48\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mumr_sum\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeepdims\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minitial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwhere\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for +: 'float' and 'str'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "columns = ['column_1', 'column_2', 'column_3', 'column_4', 'column_5', 'column_6']\n",
    "indices = [1,2,3,4,5,6]\n",
    "df1 = pd.DataFrame(np.random.rand(6,6), columns = columns, index = indices)\n",
    "\n",
    "df1.loc[2, 'column_2'] = 'string_value'\n",
    "\n",
    "mean = df1['column_2'].mean()\n",
    "print(\"Mean of column 'column_2':\")\n",
    "print(mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4784fee8-5dd9-4384-9e53-426ae6b8ffae",
   "metadata": {},
   "source": [
    "  As you can see, the code fails to find the mean of column column_2. \n",
    "    This is because the data in the second row of column column_2 is now a string variable,\n",
    "    and Pandas cannot calculate the mean of a column that contains string variables.\n",
    "    \n",
    "    To fix this error, we need to convert the string variable in the second row of column\n",
    "    column_2 to a numeric variable. We can do this using the astype() method.\n",
    "    The following code will successfully find the mean of column column_2:\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d73fbec9-0d4e-4d4f-a420-352a9cc2eed2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean of 'column_2' after replacing: 0.21712535255006013\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "columns = ['column_1', 'column_2', 'column_3', 'column_4', 'column_5', 'column_6']\n",
    "indices = [1, 2, 3, 4, 5, 6]\n",
    "\n",
    "df1 = pd.DataFrame(np.random.rand(6, 6), columns=columns, index=indices)\n",
    "\n",
    "df1.loc[2, 'column_2'] = -1\n",
    "\n",
    "column_2_mean = df1['column_2'].mean()\n",
    "print(\"Mean of 'column_2' after replacing:\", column_2_mean)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "6d9151bc-8c9d-4b68-a62d-89bbc3370d92",
   "metadata": {},
   "source": [
    "Q6. What do you understand about the windows function in pandas and list the types of windows\n",
    "    functions?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5754292b-9c15-424f-b614-99a2c789a4ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-01-01         NaN\n",
      "2023-01-02         NaN\n",
      "2023-01-03    0.149764\n",
      "2023-01-04   -0.359306\n",
      "2023-01-05   -0.628430\n",
      "2023-01-06   -0.015336\n",
      "2023-01-07    0.171758\n",
      "2023-01-08    0.420523\n",
      "2023-01-09    0.005857\n",
      "2023-01-10    1.018055\n",
      "Freq: D, Name: Value, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "\"\"\"   In pandas, a \"window function\" (also known as \"rolling\" or \"moving\" function) is a computation that\n",
    "    operates on a set of data points (values) within a defined window or range.\n",
    "    These functions are particularly useful for time-series data and other ordered data where you want to calculate aggregate measures,\n",
    "     such as moving averages, cumulative sums, or other statistics, over a sliding window.\n",
    "        \n",
    "        Window functions are often used to gain insights into trends, patterns,\n",
    "            or fluctuations in data over time or across sequences.\n",
    "            They allow you to perform calculations that take into account a specific number of preceding or succeeding data points,\n",
    "             which helps in smoothing out noise and highlighting underlying trends.\n",
    "                \n",
    "    1.Rolling Window Functions:-\n",
    "    \n",
    "    >These functions calculate statistics over a sliding window of fixed size that moves through the data.\n",
    "     You can specify the window size (number of data points) and then calculate various metrics within that window.\n",
    "        \n",
    "    >Examples include 'rolling_mean()', 'rolling_sum()', 'rolling_std()', 'rolling_max()', and 'rolling_min()'\n",
    "    \n",
    "    2.Expanding Window Functions:-\n",
    "    \n",
    "      >Expanding window functions compute statistics for all data points \n",
    "        up to a certain point in the dataset, including all preceding data points.\n",
    "        The window size increases over time.\n",
    "        \n",
    "     >Examples include \"expanding_mean()\", \"expanding_sum()\", \"expanding_std()\", \"expanding_max()\", and \"expanding_min()\"\n",
    "    \n",
    "     3.Exponential Moving Average (EMA):-\n",
    "        \n",
    "       >EMA assigns different weights to different data points, giving more importance to recent data.\n",
    "          It's often used for smoothing data and is a type of rolling window function.\n",
    "        \n",
    "        >Example: 'ewm()' 'function with options like span', 'halflife', or 'com.'\n",
    "        \n",
    "    4.Window Apply Functions:-\n",
    "    \n",
    "      > These functions allow you to apply a custom function to a rolling window of data.\n",
    "        \n",
    "      >Example: 'rolling_apply()'.\n",
    "    5.Window Aggregation Functions:-\n",
    "    \n",
    "    \n",
    "     >These functions aggregate data within a window to produce a single value for each window.\n",
    "        \n",
    "     >Example: 'rolling_agg()'.\"\"\"\n",
    "    \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "dates = pd.date_range('2023-01-01', periods=10, freq='D')\n",
    "data = np.random.randn(10)\n",
    "df = pd.DataFrame(data, index=dates, columns=['Value'])\n",
    "\n",
    "rolling_mean = df['Value'].rolling(window=3).mean()\n",
    "\n",
    "print(rolling_mean)    "
   ]
  },
  {
   "cell_type": "raw",
   "id": "ef4a2d10-ac61-4823-8a23-becb06400ff0",
   "metadata": {},
   "source": [
    "Q7. Write a code to print only the current month and year at the time of answering this question.\n",
    "   [Hint: Use pandas.datetime function]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "281b64af-8614-4d14-b792-2f1fcb5913db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current month: 8\n",
      "Current year: 2023\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "current_date = pd.Timestamp.now()\n",
    "\n",
    "current_month = current_date.month\n",
    "current_year = current_date.year\n",
    "\n",
    "print(f\"Current month: {current_month}\")\n",
    "print(f\"Current year: {current_year}\")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "ea749896-92d2-4941-adc3-a7e527a5f41a",
   "metadata": {},
   "source": [
    "Q8. Write a Python program that takes in two dates as input (in the format YYYY-MM-DD) and\n",
    "    calculates the difference between them in days, hours, and minutes using Pandas time delta. The\n",
    "    program should prompt the user to enter the dates and display the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5c9d8835-edd8-4098-8aac-26cd1813a561",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter the first date (YYYY-MM-DD):  2023-08-01\n",
      "Enter the second date (YYYY-MM-DD):  2023-08-31\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time difference: 30 days, 0 hours, 0 minutes\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def calculate_time_difference(date1, date2):\n",
    "    try:\n",
    "        \n",
    "        timestamp1 = pd.Timestamp(date1)\n",
    "        timestamp2 = pd.Timestamp(date2)\n",
    "        \n",
    "        \n",
    "        time_difference = timestamp2 - timestamp1\n",
    "        \n",
    "        \n",
    "        days = time_difference.days\n",
    "        hours, remainder = divmod(time_difference.seconds, 3600)\n",
    "        minutes, seconds = divmod(remainder, 60)\n",
    "        \n",
    "        \n",
    "        print(f\"Time difference: {days} days, {hours} hours, {minutes} minutes\")\n",
    "    except Exception as e:\n",
    "        print(\"Error:\", e)\n",
    "\n",
    "\n",
    "date1 = input(\"Enter the first date (YYYY-MM-DD): \")\n",
    "date2 = input(\"Enter the second date (YYYY-MM-DD): \")\n",
    "\n",
    "\n",
    "calculate_time_difference(date1, date2)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "e7c54261-d623-40b1-9022-ae6a1291261f",
   "metadata": {},
   "source": [
    "Q9. Write a Python program that reads a CSV file containing categorical data and converts a specified\n",
    "    column to a categorical data type. The program should prompt the user to enter the file path, column\n",
    "    name, and category order, and then display the sorted data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a2786a2e-f87c-42aa-bcf3-45dfea32facd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter the file path (CSV):  sonu\n",
      "Enter the column name to convert:  f\n",
      "Enter the category order (comma-separated):  python\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: [Errno 2] No such file or directory: 'sonu'\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def convert_to_categorical(file_path, column_name, category_order):\n",
    "    try:\n",
    "        \n",
    "        df = pd.read_csv(file_path)\n",
    "        \n",
    "        \n",
    "        df[column_name] = pd.Categorical(df[column_name], categories=category_order, ordered=True)\n",
    "        \n",
    "        \n",
    "        sorted_df = df.sort_values(by=[column_name])\n",
    "        \n",
    "               \n",
    "        print(sorted_df)\n",
    "    except Exception as e:\n",
    "        print(\"Error:\", e)\n",
    "\n",
    "\n",
    "file_path = input(\"Enter the file path (CSV): \")\n",
    "column_name = input(\"Enter the column name to convert: \")\n",
    "category_order = input(\"Enter the category order (comma-separated): \").split(',')\n",
    "\n",
    "convert_to_categorical(file_path, column_name, category_order)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "2a8c1683-8a41-47b1-9349-4e34c10ac02c",
   "metadata": {},
   "source": [
    "Q10. Write a Python program that reads a CSV file containing sales data for different products and\n",
    "     visualizes the data using a stacked bar chart to show the sales of each product category over time. The\n",
    "     program should prompt the user to enter the file path and display the chart."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "276bb337-0547-41cf-83d6-ca7cc5c9e51d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter the file path (CSV):  pankaj\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: [Errno 2] No such file or directory: 'pankaj'\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def visualize_sales(file_path):\n",
    "    try:\n",
    "        \n",
    "        df = pd.read_csv(file_path)\n",
    "        \n",
    "        \n",
    "        pivot_df = df.pivot_table(index='Date', columns='ProductCategory', values='Sales', aggfunc='sum')\n",
    "        \n",
    "    \n",
    "        pivot_df.plot(kind='bar', stacked=True)\n",
    "        \n",
    "        \n",
    "        plt.title('Sales by Product Category Over Time')\n",
    "        plt.xlabel('Date')\n",
    "        plt.ylabel('Sales')\n",
    "        \n",
    "        \n",
    "        plt.show()\n",
    "    except Exception as e:\n",
    "        print(\"Error:\", e)\n",
    "\n",
    "\n",
    "file_path = input(\"Enter the file path (CSV): \")\n",
    "\n",
    "\n",
    "visualize_sales(file_path)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "5e4cdcae-6832-4c8b-9d0c-2a13e78f3a4e",
   "metadata": {},
   "source": [
    "Q11. You are given a CSV file containing student data that includes the student ID and their test score. Write\n",
    "     a Python program that reads the CSV file, calculates the mean, median, and mode of the test scores, and\n",
    "     displays the results in a table.\n",
    "        \n",
    "        \n",
    "The program should do the followingM\n",
    "  I Prompt the user to enter the file path of the CSV file containing the student dataR\n",
    "  I Read the CSV file into a Pandas DataFrameR\n",
    "  I Calculate the mean, median, and mode of the test scores using Pandas toolsR\n",
    "  I Display the mean, median, and mode in a table.\n",
    "Assume the CSV file contains the following columnsM\n",
    "  I Student ID: The ID of the studentR\n",
    "  I Test Score: The score of the student's test.\n",
    "Example usage of the program:\n",
    "Enter the file path of the CSV file containing the student data: student_data.csv\n",
    "+-----------+--------+\n",
    "| Statistic | Value |\n",
    "+-----------+--------+\n",
    "| Mean | 79.6 |\n",
    "| Median | 82 |\n",
    "| Mode | 85, 90 |\n",
    "+-----------+--------+\n",
    "Assume that the CSV file student_data.csv contains the following data:\n",
    "Student ID,Test Score\n",
    "1,85\n",
    "2,90\n",
    "3,80\n",
    "4,75\n",
    "5,85\n",
    "6,82\n",
    "7,78\n",
    "8,85\n",
    "9,90\n",
    "10,85\n",
    "The program should calculate the mean, median, and mode of the test scores and display the results\n",
    "in a table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bc70f9d9-7677-4723-ad83-664a73168423",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tabulate'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mstatistics\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtabulate\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m tabulate\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcalculate_statistics\u001b[39m(file_path):\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tabulate'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import statistics\n",
    "from tabulate import tabulate\n",
    "\n",
    "\n",
    "def calculate_statistics(file_path):\n",
    "    try:\n",
    "        \n",
    "        df = pd.read_csv(file_path)\n",
    "        \n",
    "        \n",
    "        mean_score = df['Test Score'].mean()\n",
    "        median_score = df['Test Score'].median()\n",
    "        mode_scores = statistics.multimode(df['Test Score'])\n",
    "        \n",
    "               \n",
    "        results = [\n",
    "            [\"Mean\", mean_score],\n",
    "            [\"Median\", median_score],\n",
    "            [\"Mode\", ', '.join(map(str, mode_scores))]\n",
    "        ]\n",
    "        \n",
    "        print(tabulate(results, headers=[\"Statistic\", \"Value\"]))\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(\"Error:\", e)\n",
    "\n",
    "\n",
    "file_path = input(\"Enter the file path of the CSV file containing the student data: \")\n",
    "\n",
    "\n",
    "calculate_statistics(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f9dc5eb-1f57-4296-9740-5bd47deb5a1d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
